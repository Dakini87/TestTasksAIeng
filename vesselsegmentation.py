# -*- coding: utf-8 -*-
"""VesselSegmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b4UOxHLxl-LiMfsGb-LWbjy5y3n5AxxE

### 1. Importing the necessary libraries
"""

from google.colab import drive
import zipfile
import os
import shutil
import SimpleITK as sitk
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from ipywidgets import interact
import ipywidgets as widgets
from torch.utils.data import Dataset, DataLoader
import torch
import random
from torchvision import transforms
from scipy import ndimage
import glob
from sklearn.model_selection import train_test_split
import torch.nn as nn
import torch.nn.functional as F
import segmentation_models_pytorch as smp
import torch.optim as optim
from tqdm.notebook import tqdm
import time
from skimage import morphology, measure, filters
from mpl_toolkits.mplot3d import Axes3D
from skimage import measure

"""### 2. Setting Up Environment"""

# Mounting Google Drive
drive.mount('/content/drive')

# Defining the path to the uploaded dataset
dataset_path = "/content/drive/MyDrive/CT_Segmentation/VS_Segmentation.zip"
extraction_path = "/content/CT_Segmentation/"

# Extracting the dataset
with zipfile.ZipFile(dataset_path, 'r') as zip_ref:
    zip_ref.extractall(extraction_path)

# Verifying the extraction
print("Extracted folders and files:")
print(os.listdir(extraction_path))

"""### 3. Dataset Exploration and Loading"""

# Checking dataset structure
for root, dirs, files in os.walk(extraction_path):
    print(f"Directory: {root}")
    # Displaying first 3 files in each folder
    for file in files[:3]:
        print(f"  {file}")

"""### 4. Organizing the Data Structure into Scans, Masks, and Examples"""

# Paths
base_path = "/content/CT_Segmentation/VS_Segmentation/"
scans_path = "/content/CT_Segmentation/Scans/"
masks_path = "/content/CT_Segmentation/Masks/"
examples_path = "/content/CT_Segmentation/Examples/"

# Creating new folders
os.makedirs(scans_path, exist_ok=True)
os.makedirs(masks_path, exist_ok=True)
os.makedirs(examples_path, exist_ok=True)

# Scan files
for subdir in ['1-5', '6-10', '11-15', '16-20']:
    subdir_path = os.path.join(base_path, subdir)
    for file in os.listdir(subdir_path):
        if file.endswith('.mhd') or file.endswith('.raw'):
            src = os.path.join(subdir_path, file)
            dst = os.path.join(scans_path, file)
            shutil.move(src, dst)

# Lung masks
lung_mask_path = os.path.join(base_path, "1-20")
for file in os.listdir(lung_mask_path):
    if file.endswith('.mhd') or file.endswith('.raw'):
        src = os.path.join(lung_mask_path, file)
        dst = os.path.join(masks_path, file)
        shutil.move(src, dst)

# Example files
example_path = os.path.join(base_path, "examples")
shutil.move(example_path, examples_path)

print("Data reorganization complete.")
print(f"Scans: {len(os.listdir(scans_path))} files")
print(f"Masks: {len(os.listdir(masks_path))} files")
print(f"Examples: {os.listdir(examples_path)}")

# Verifing that the files are correctly organized
print("Scans Directory Content:")
print(os.listdir(scans_path)[:5])

print("\nMasks Directory Content:")
print(os.listdir(masks_path)[:5])

print("\nExamples Directory Content:")
print(os.listdir(examples_path))

def load_scan(scan_path):
    """Load the scan using SimpleITK and normalize the voxel values."""
    # Reading the scan
    scan = sitk.ReadImage(scan_path)
    scan_array = sitk.GetArrayFromImage(scan)

    # Normalizing voxel values to range [0, 1]
    scan_array = (scan_array - np.min
     (scan_array)) / (np.max(scan_array) - np.min(scan_array))

    return scan_array

def load_mask(mask_path):
    """Load the mask using SimpleITK."""
    mask = sitk.ReadImage(mask_path)
    mask_array = sitk.GetArrayFromImage(mask)

    return mask_array

# Loading a sample scan and mask
sample_scan_path = os.path.join(scans_path, "VESSEL12_05.mhd")
sample_mask_path = os.path.join(masks_path, "VESSEL12_05.mhd")

scan_array = load_scan(sample_scan_path)
mask_array = load_mask(sample_mask_path)

print("Scan Shape:", scan_array.shape)
print("Mask Shape:", mask_array.shape)

"""### 5. Visualizing a Sample Scan and Mask"""

# Function to visualize slices of the scan and mask
def visualize_slice(slice_idx, scan_array, mask_array=None):
    """
    Visualize a slice of the scan and corresponding mask
    """
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 2 if mask_array is not None else 1, 1)
    plt.imshow(scan_array[slice_idx], cmap='gray')
    plt.title(f'CT Scan Slice {slice_idx}')
    plt.colorbar()

    if mask_array is not None:
        plt.subplot(1, 2, 2)
        plt.imshow(mask_array[slice_idx], cmap='viridis')
        plt.title(f'Mask Slice {slice_idx}')
        plt.colorbar()

    plt.tight_layout()
    plt.show()

# Creating an interactive slider to visualize different slices
def explore_scan_and_mask(scan_array, mask_array=None):
    """
    Create an interactive slider to explore the scan and mask
    """
    max_slice = scan_array.shape[0] - 1

    interact(
        visualize_slice,
        slice_idx=widgets.IntSlider(min=0, max=max_slice,
                                    step=1, value=max_slice//2),
        scan_array=widgets.fixed(scan_array),
        mask_array=widgets.fixed(mask_array)
    )

# Exploring the loaded scan and mask
explore_scan_and_mask(scan_array, mask_array)

"""### 6. Preparing the Dataset for Training

"""

class VesselDataset(Dataset):
    def __init__(self, scan_paths, mask_paths=None,
                 transform=None, slice_selection='random',
                 slices_per_volume=10):
        """
        Dataset for vessel segmentation

        Args:
            scan_paths: List of paths to the scan files
            mask_paths: List of paths to the mask files (None for test set)
            transform: Data augmentation transforms
            slice_selection: How to select slices ('random', 'middle', 'all')
            slices_per_volume: Number of slices to select per volume
            if slice_selection='random'
        """
        self.scan_paths = scan_paths
        self.mask_paths = mask_paths
        self.transform = transform
        self.slice_selection = slice_selection
        self.slices_per_volume = slices_per_volume

        # Creating a mapping of all available slices
        self.slices = []
        for idx, scan_path in enumerate(scan_paths):
            # Loading scan to get dimensions
            scan = sitk.ReadImage(scan_path)
            scan_array = sitk.GetArrayFromImage(scan)
            n_slices = scan_array.shape[0]

            if slice_selection == 'all':
                # Using all slices
                self.slices.extend([(idx, s) for s in range(n_slices)])
            elif slice_selection == 'middle':
                # Using middle slice
                middle_slice = n_slices // 2
                self.slices.append((idx, middle_slice))
            elif slice_selection == 'random':
                # Randomly selectig slices_per_volume slices
                selected_slices = random.sample(range(n_slices),
                                                min(slices_per_volume,
                                                    n_slices))
                self.slices.extend([(idx, s) for s in selected_slices])

    def __len__(self):
        return len(self.slices)

    def __getitem__(self, idx):
        volume_idx, slice_idx = self.slices[idx]

        # Loading the scan
        scan_path = self.scan_paths[volume_idx]
        scan = sitk.ReadImage(scan_path)
        scan_array = sitk.GetArrayFromImage(scan)

        # Extracting the slice and normalize
        slice_data = scan_array[slice_idx].astype(np.float32)
        slice_data = (slice_data - np.min(slice_data)
        ) / (np.max(slice_data) - np.min(slice_data) + 1e-8)

        # Converting to tensor
        slice_tensor = torch.from_numpy(slice_data).unsqueeze(0)

        # Loading the corresponding mask slice
        if self.mask_paths is not None:
            mask_path = self.mask_paths[volume_idx]
            mask = sitk.ReadImage(mask_path)
            mask_array = sitk.GetArrayFromImage(mask)

            # Extracting the slice and binarize
            mask_slice = mask_array[slice_idx].astype(np.float32)
            # Assuming values > 0 are vessels
            mask_slice = (mask_slice > 0).astype(np.float32)

            # Converting to tensor
            mask_tensor = torch.from_numpy(mask_slice).unsqueeze(0)

            # Applying transforms
            if self.transform:
                # Stacking input and target for consistent transforms
                combined = torch.cat([slice_tensor, mask_tensor], dim=0)
                combined = self.transform(combined)

                # Unstacking after transform
                slice_tensor = combined[0].unsqueeze(0)
                mask_tensor = combined[1].unsqueeze(0)

            return slice_tensor, mask_tensor
        else:
            # Returning only the input slice for test
            if self.transform:
                slice_tensor = self.transform(slice_tensor)
            return slice_tensor

# Defining data augmentation transforms
def get_transforms(training=True):

    if training:
        return transforms.Compose([
            transforms.RandomHorizontalFlip(),
            transforms.RandomVerticalFlip(),
            transforms.RandomAffine(degrees=15,
                                    translate=(0.1, 0.1),
                                    scale=(0.9, 1.1)),
        ])
    else:
        return None

"""### 7. Creating Train/ Validation/ Test Splits"""

# Getting all scan and mask files
scan_files = sorted(glob.glob(os.path.join(scans_path, "*.mhd")))
mask_files = sorted(glob.glob(os.path.join(masks_path, "*.mhd")))

print(f"Found {len(scan_files)} scan files and {len(mask_files)} mask files")

# Making sure they match
scan_basenames = [os.path.basename(f) for f in scan_files]
mask_basenames = [os.path.basename(f) for f in mask_files]

# Checking if they match
if set(scan_basenames) != set(mask_basenames):
    print("Warning: Scan and mask files don't match!")
    # Only matching files
    matching_scans = []
    matching_masks = []
    for i, scan_file in enumerate(scan_files):
        scan_name = os.path.basename(scan_file)
        if scan_name in mask_basenames:
            mask_idx = mask_basenames.index(scan_name)
            matching_scans.append(scan_file)
            matching_masks.append(mask_files[mask_idx])

    scan_files = matching_scans
    mask_files = matching_masks
    print(f"Using {len(scan_files)} matching scan-mask pairs")

# Splitting into train, validation, and test sets
train_scans, temp_scans, train_masks, temp_masks = train_test_split(
    scan_files, mask_files, test_size=0.3, random_state=42
)

val_scans, test_scans, val_masks, test_masks = train_test_split(
    temp_scans, temp_masks, test_size=0.5, random_state=42
)

print(f"Train: {len(train_scans)} scans")
print(f"Validation: {len(val_scans)} scans")
print(f"Test: {len(test_scans)} scans")

# Creating datasets
train_transforms = get_transforms(training=True)
val_transforms = get_transforms(training=False)

train_dataset = VesselDataset(train_scans, train_masks,
                              transform=train_transforms,
                              slice_selection='random',
                              slices_per_volume=20)
val_dataset = VesselDataset(val_scans, val_masks,
                            transform=val_transforms,
                            slice_selection='random',
                            slices_per_volume=10)
test_dataset = VesselDataset(test_scans, test_masks,
                             transform=val_transforms,
                             slice_selection='random',
                             slices_per_volume=10)

# Createing dataloaders
batch_size = 8
train_loader = DataLoader(train_dataset,
                          batch_size=batch_size,
                          shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset,
                        batch_size=batch_size,
                        shuffle=False, num_workers=0)
test_loader = DataLoader(test_dataset,
                         batch_size=batch_size,
                         shuffle=False, num_workers=0)

# Checking a batch from the train loader
for images, masks in train_loader:
    print(f"Batch shape - Images: {images.shape}, \
    Masks: {masks.shape}")
    print(f"Data range - Images: [{images.min():.4f}, \
    {images.max():.4f}], Masks: [{masks.min():.4f}, {masks.max():.4f}]")
    break

"""### 8. Defining the U-Net Model"""

# Using a pre-trained U-Net from segmentation_models_pytorch
def get_model(pretrained=True):
    """
    Getting a pre-trained U-Net model with a ResNet34 encoder
    """
    model = smp.Unet(
        # Choosing encoder, resnet34 as its a good balance of speed and accuracy
        encoder_name="resnet34",
        # Using a pre-trained weight on ImageNet
        encoder_weights="imagenet" if pretrained else None,
        # Input channels, 1 for grayscale
        in_channels=1,
        # Output channels, 1 for biniary segmentation
        classes=1,
        # Final activation function
        activation='sigmoid',
    )
    return model

# Initializig the model
model = get_model(pretrained=True)

# Model summary
print(model)

"""### 9. Defining Loss Function, Metrics, and Optimizer"""

# Defining loss function
def dice_loss(pred, target, smooth=1.0):
    """
    Differentiable Dice coefficient for training
    """
    pred = pred.contiguous()
    target = target.contiguous()

    intersection = (pred * target).sum(dim=2).sum(dim=2)

    loss = 1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2)
    + target.sum(dim=2).sum(dim=2) + smooth))

    return loss.mean()

def combined_loss(pred, target, bce_weight=0.5, dice_weight=0.5):
    """
    Combined BCE and Dice loss
    """
    bce = F.binary_cross_entropy(pred, target, reduction='mean')
    dice = dice_loss(pred, target)

    return bce_weight * bce + dice_weight * dice

# Defining evaluation metrics
def dice_coefficient(pred, target, threshold=0.5, smooth=1e-5):
    """
    Calculating Dice coefficient for evaluation
    """
    pred = (pred > threshold).float()
    intersection = (pred * target).sum().item()
    return (2. * intersection + smooth) / (pred.sum().item()
    + target.sum().item() + smooth)

def IoU(pred, target, threshold=0.5, smooth=1e-5):
    """
    Calculating Intersection over Union (IoU) for evaluation
    """
    pred = (pred > threshold).float()
    intersection = (pred * target).sum().item()
    union = pred.sum().item() + target.sum().item() - intersection
    return (intersection + smooth) / (union + smooth)

# Initializing the model, optimizer, and scheduler
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

model = get_model(pretrained=True).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,
                                                 'min', patience=3, verbose=True)

"""### 10. Defining Training and Validation Functions"""

def train_epoch(model, dataloader, optimizer, device):
    """
    Train for one epoch
    """
    model.train()
    epoch_loss = 0
    epoch_dice = 0
    epoch_iou = 0
    num_batches = len(dataloader)

    with tqdm(dataloader, unit="batch") as tepoch:
        for images, targets in tepoch:
            # Moving tensors to the configured device
            images = images.to(device)
            targets = targets.to(device)

            # Forward pass
            outputs = model(images)
            loss = combined_loss(outputs, targets)

            # Backward pass and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Calculate metrics
            dice = dice_coefficient(outputs.detach(), targets.detach())
            iou = IoU(outputs.detach(), targets.detach())

            # Updating running metrics
            epoch_loss += loss.item()
            epoch_dice += dice
            epoch_iou += iou

            # Updating progress bar
            tepoch.set_postfix(loss=loss.item(), dice=dice, iou=iou)

    return epoch_loss / num_batches, epoch_dice / num_batches, epoch_iou / num_batches

def validate(model, dataloader, device):
    """
    Validating the model
    """
    model.eval()
    val_loss = 0
    val_dice = 0
    val_iou = 0
    num_batches = len(dataloader)

    with torch.no_grad():
        with tqdm(dataloader, unit="batch") as tepoch:
            for images, targets in tepoch:
                # Moving tensors to the configured device
                images = images.to(device)
                targets = targets.to(device)

                # Forward pass
                outputs = model(images)
                loss = combined_loss(outputs, targets)

                # Calculating metrics
                dice = dice_coefficient(outputs, targets)
                iou = IoU(outputs, targets)

                # Updating running metrics
                val_loss += loss.item()
                val_dice += dice
                val_iou += iou

                # Updating progress bar
                tepoch.set_postfix(val_loss=loss.item(), val_dice=dice, val_iou=iou)

    return val_loss / num_batches, val_dice / num_batches, val_iou / num_batches

"""### 11. Training the Model


"""

def train_model(model, train_loader,
                val_loader, optimizer, scheduler, device, num_epochs=10):
    """
    Training the model
    """
    # Storing metrics
    history = {
        'train_loss': [], 'train_dice': [], 'train_iou': [],
        'val_loss': [], 'val_dice': [], 'val_iou': [],
        'best_epoch': 0, 'best_val_dice': 0
    }

    best_val_dice = 0.0

    # Saving model path
    model_path = 'best_vessel_segmentation_model.pth'

    start_time = time.time()

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")

        # Training
        train_loss, train_dice, train_iou = train_epoch(
            model, train_loader, optimizer, device)

        # Validating
        val_loss, val_dice, val_iou = validate(model, val_loader, device)

        # Updating learning rate
        scheduler.step(val_loss)

        # Savint the metrics
        history['train_loss'].append(train_loss)
        history['train_dice'].append(train_dice)
        history['train_iou'].append(train_iou)
        history['val_loss'].append(val_loss)
        history['val_dice'].append(val_dice)
        history['val_iou'].append(val_iou)

        # Epoch summary
        print(f"Train Loss: {train_loss:.4f}, \
        Dice: {train_dice:.4f}, IoU: {train_iou:.4f}")
        print(f"Val Loss: {val_loss:.4f}, \
        Dice: {val_dice:.4f}, IoU: {val_iou:.4f}")

        # Saving the best model
        if val_dice > best_val_dice:
            best_val_dice = val_dice
            history['best_epoch'] = epoch
            history['best_val_dice'] = best_val_dice
            torch.save(model.state_dict(), model_path)
            print(f"Model saved at epoch {epoch+1} \
            (Validation Dice: {val_dice:.4f})")

    training_time = time.time() - start_time
    print(f"Training completed in {training_time/60:.2f} minutes")

    # Loading the best model
    model.load_state_dict(torch.load(model_path))

    return model, history

# Training the model (adjust num_epochs as needed)
num_epochs = 5  # Start with a small number to test the pipeline
trained_model, history = train_model(
    model, train_loader, val_loader,
    optimizer, scheduler, device, num_epochs=num_epochs
)

"""### 12. Visualizing Training Results"""

# Plotting the training history
plt.figure(figsize=(16, 6))

plt.subplot(1, 2, 1)
plt.plot(history['train_loss'], label='Train Loss')
plt.plot(history['val_loss'], label='Validation Loss')
plt.title('Loss History')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history['train_dice'], label='Train Dice')
plt.plot(history['val_dice'], label='Validation Dice')
plt.plot(history['train_iou'], label='Train IoU')
plt.plot(history['val_iou'], label='Validation IoU')
plt.title('Metrics History')
plt.xlabel('Epoch')
plt.ylabel('Score')
plt.legend()

plt.tight_layout()
plt.show()

print(f"Best model saved at epoch {history['best_epoch']+1} \
with validation Dice coefficient: {history['best_val_dice']:.4f}")

"""### 13 Implementing Post-Processing Techniques"""

def post_process_segmentation(prediction, min_size=100, methods=None):
    """
    Applying post-processing techniques to refine the segmentation

    Args:
        prediction: Binary prediction mask (numpy array)
        min_size: Minimum connected component size to retain
        methods: List of methods to apply ('remove_small',
        'fill_holes', 'smoothing', 'lung_mask')

    Returns:
        Refined binary mask
    """
    if methods is None:
        methods = ['remove_small', 'fill_holes', 'smoothing']

    # Making sure we're working with binary data
    binary_pred = prediction > 0.5

    # Applying post-processing methods
    for method in methods:
        if method == 'remove_small':
            # Removing small connected components
            labeled_mask, num_features = ndimage.label(binary_pred)
            component_sizes = np.bincount(labeled_mask.ravel())
            component_sizes[0] = 0
            too_small = component_sizes < min_size
            too_small_mask = too_small[labeled_mask]
            binary_pred[too_small_mask] = 0

        elif method == 'fill_holes':
            # Filling holes in connected components
            binary_pred = ndimage.binary_fill_holes(binary_pred)

        elif method == 'smoothing':
            # Applyig morphological closing to smooth boundaries
            binary_pred = morphology.binary_closing(binary_pred,
                                                    morphology.disk(2))

    return binary_pred

# Function to apply post-processing to a batch
def apply_post_processing(model_outputs, threshold=0.5, post_process=True):
    """
    Applyig post-processing to model outputs

    Args:
        model_outputs: Model prediction tensor
        threshold: Threshold for initial binarization
        post_process: Whether to apply post-processing

    Returns:
        Processed predictions
    """
    # Converting to numpy array
    outputs_np = model_outputs.detach().cpu().numpy()

    processed_outputs = []
    for output in outputs_np:
        # Squeezing out channel dimension
        output = output.squeeze(0)

        # Applying threshold
        binary_output = (output > threshold).astype(np.float32)

        if post_process:
            # Applying post-processing
            processed = post_process_segmentation(binary_output)
            processed_outputs.append(processed)
        else:
            processed_outputs.append(binary_output)

    return np.array(processed_outputs)

"""### 14. Evaluating on Test Set with Post-Processing"""

def evaluate_model(model, test_loader, device, post_process=True):
    """
    Evaluatinh the model on the test set
    """
    model.eval()

    dice_scores = {'raw': [], 'processed': []} if post_process else {'raw': []}
    iou_scores = {'raw': [], 'processed': []} if post_process else {'raw': []}

    all_preds = []
    all_targets = []

    with torch.no_grad():
        for images, targets in tqdm(test_loader, desc="Evaluating"):
            images = images.to(device)
            targets = targets.to(device)

            # Forward pass
            outputs = model(images)

            # Calculating metrics for raw predictions
            raw_dice = dice_coefficient(outputs, targets)
            raw_iou = IoU(outputs, targets)

            dice_scores['raw'].append(raw_dice)
            iou_scores['raw'].append(raw_iou)

            # Applying post-processing if enabled
            if post_process:
                # Processing batch predictions
                processed_preds = apply_post_processing(outputs)

                # Adding channel dimension to match target shape
                processed_preds = processed_preds[:, np.newaxis, :, :]
                processed_preds_tensor = torch.tensor(processed_preds,
                                                      device=device).float()

                # Calculating metrics for processed predictions
                proc_dice = dice_coefficient(processed_preds_tensor, targets)
                proc_iou = IoU(processed_preds_tensor, targets)

                dice_scores['processed'].append(proc_dice)
                iou_scores['processed'].append(proc_iou)

            # Storing predictions and targets for visualization
            all_preds.append(outputs.cpu().numpy())
            all_targets.append(targets.cpu().numpy())

    # Calculating average metrics
    avg_metrics = {
        'raw_dice': np.mean(dice_scores['raw']),
        'raw_iou': np.mean(iou_scores['raw'])
    }

    if post_process:
        avg_metrics.update({
            'processed_dice': np.mean(dice_scores['processed']),
            'processed_iou': np.mean(iou_scores['processed'])
        })

    return avg_metrics, all_preds, all_targets

# Evaluating the model on test set
print("Evaluating on test set...")
test_metrics, test_preds, test_targets = evaluate_model(
    trained_model, test_loader, device, post_process=True)

# Test metrics
for metric_name, value in test_metrics.items():
    print(f"{metric_name}: {value:.4f}")

"""### 15. Visualizing Segmentation Results and Creating Comparison Visualizations"""

def visualize_results(images, targets,
                      raw_preds, processed_preds=None, num_samples=3):
    """
    Visualizing segmentation results
    """
    # Select random samples from the first batch
    indices = np.random.choice(images.shape[0],
                               min(num_samples,
                                   images.shape[0]), replace=False)

    for i, idx in enumerate(indices):
        img = images[idx, 0].squeeze()
        target = targets[idx, 0].squeeze()
        raw_pred = raw_preds[idx, 0].squeeze()

        n_cols = 4 if processed_preds is not None else 3
        plt.figure(figsize=(n_cols * 4, 4))

        # Original image
        plt.subplot(1, n_cols, 1)
        plt.imshow(img, cmap='gray')
        plt.title('Original Image')
        plt.axis('off')

        # Ground truth
        plt.subplot(1, n_cols, 2)
        plt.imshow(target, cmap='viridis')
        plt.title('Ground Truth')
        plt.axis('off')

        # Raw prediction
        plt.subplot(1, n_cols, 3)
        plt.imshow((raw_pred > 0.5).astype(float), cmap='viridis')
        plt.title('Raw Prediction')
        plt.axis('off')

        # Post-processed prediction
        if processed_preds is not None:
            proc_pred = processed_preds[idx].squeeze()
            plt.subplot(1, n_cols, 4)
            plt.imshow(proc_pred, cmap='viridis')
            plt.title('Post-processed')
            plt.axis('off')

        plt.tight_layout()
        plt.show()

# Visualizing a batch from the test set
for images, targets in test_loader:
    # Forward pass
    images_gpu = images.to(device)
    with torch.no_grad():
        outputs = trained_model(images_gpu)

    # Applying post-processing
    processed_preds = apply_post_processing(outputs)

    # Visualizing
    visualize_results(
        images.numpy(),
        targets.numpy(),
        outputs.cpu().numpy(),
        processed_preds,
        num_samples=3
    )
    break

"""### 16. Creating 3D Visualization"""

def create_3d_visualization(scan_path, trained_model,
                            device, output_path=None,
                            threshold=0.5, post_process=True):
    """
    Creating a 3D visualization of the vessel segmentation

    Args:
        scan_path: Path to the CT scan
        trained_model: Trained model for segmentation
        device: Device for inference
        output_path: Path to save the 3D mesh
        threshold: Threshold for binarization
        post_process: Whether to apply post-processing
    """
    # Loading the scan
    scan = sitk.ReadImage(scan_path)
    scan_array = sitk.GetArrayFromImage(scan)

    # Normalizing the scan
    scan_array = (scan_array - np.min(scan_array))
    / (np.max(scan_array) - np.min(scan_array))

    # Processing the volume slice by slice
    segmentation = np.zeros_like(scan_array, dtype=np.float32)

    print(f"Processing volume of shape {scan_array.shape}...")

    batch_size = 8
    for start_idx in tqdm(range(0, scan_array.shape[0], batch_size)):
        end_idx = min(start_idx + batch_size, scan_array.shape[0])
        batch_slices = scan_array[start_idx:end_idx]

        # Preparing batch for model
        batch_tensor = torch.tensor(batch_slices,
                                    device=device).float().unsqueeze(1)

        # Running model inference
        with torch.no_grad():
            batch_preds = trained_model(batch_tensor)

        # Post-process if enabled
        if post_process:
            batch_preds_np = apply_post_processing(batch_preds)
        else:
            batch_preds_np = batch_preds.cpu().numpy().squeeze(1)
            batch_preds_np = (batch_preds_np > threshold).astype(np.float32)

        # Storing in output volume
        segmentation[start_idx:end_idx] = batch_preds_np

    # Creating 3D visualization
    print("Creating 3D mesh...")
    verts, faces, _, _ = measure.marching_cubes(segmentation, level=0.5)

    # Displaying the 3D mesh
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(111, projection='3d')

    # Creating mesh
    mesh = ax.plot_trisurf(verts[:, 0], verts[:, 1], verts[:, 2],
                          triangles=faces, cmap=cm.viridis,
                          linewidth=0.1, alpha=0.9)

    # Limits
    ax.set_xlim(0, segmentation.shape[2])
    ax.set_ylim(0, segmentation.shape[1])
    ax.set_zlim(0, segmentation.shape[0])

    # Labels
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')

    plt.tight_layout()
    plt.title('3D Vessel Segmentation')

    if output_path:
        plt.savefig(output_path)

    plt.show()

    # Saving the mesh as an STL file
    if output_path and output_path.endswith('.stl'):
        from stl import mesh as stl_mesh

        # Creating the mesh
        vessel_mesh = stl_mesh.Mesh(np.zeros(faces.shape[0],
                                             dtype=stl_mesh.Mesh.dtype))
        for i, f in enumerate(faces):
            for j in range(3):
                vessel_mesh.vectors[i][j] = verts[f[j],:]

        # Writing the mesh to file
        vessel_mesh.save(output_path)
        print(f"3D mesh saved to {output_path}")

    return segmentation

# Selecting a sample scan for 3D visualization
sample_test_scan = test_scans[0]
print(f"Creating 3D visualization for: {os.path.basename(sample_test_scan)}")

# Creating the 3D visualization
segmentation_3d = create_3d_visualization(
    sample_test_scan,
    trained_model,
    device,
    output_path="vessel_segmentation_3d.png",
    post_process=True
)

"""### 17. Summary and Final Evaluation"""

def create_summary_report(history, test_metrics, scan_info=None):
    """
    Creating a summary report of the model's performance
    """
    print("=" * 50)
    print("VESSEL SEGMENTATION PROJECT SUMMARY")
    print("=" * 50)

    # Dataset information
    print("\n## Dataset Information")
    print(f"Number of training scans: {len(train_scans)}")
    print(f"Number of validation scans: {len(val_scans)}")
    print(f"Number of test scans: {len(test_scans)}")

    if scan_info:
        print(f"Average volume size: {scan_info['avg_size']}")
        print(f"Resolution: {scan_info['resolution']}")

    # Model information
    print("\n## Model Information")
    print("Architecture: U-Net with ResNet34 encoder")
    print("Pre-trained: Yes (ImageNet weights)")
    print(f"Best model achieved at epoch: {history['best_epoch']+1}")

    # Performance metrics
    print("\n## Performance Metrics")
    print(f"Best validation Dice coefficient: {history['best_val_dice']:.4f}")
    print("\nTest Set Performance:")
    print(f"Raw prediction Dice coefficient: {test_metrics['raw_dice']:.4f}")
    print(f"Raw prediction IoU: {test_metrics['raw_iou']:.4f}")

    if 'processed_dice' in test_metrics:
        print(f"Post-processed Dice coefficient: {test_metrics['processed_dice']:.4f}")
        print(f"Post-processed IoU: {test_metrics['processed_iou']:.4f}")

        # Comparing raw vs post-processed
        dice_improvement = (test_metrics['processed_dice']
                            - test_metrics['raw_dice']) / test_metrics['raw_dice'] * 100
        iou_improvement = (test_metrics['processed_iou']
                           - test_metrics['raw_iou']) / test_metrics['raw_iou'] * 100

        print(f"\nDice improvement with post-processing: {dice_improvement:.2f}%")
        print(f"IoU improvement with post-processing: {iou_improvement:.2f}%")

    # Improvement techniques
    print("\n## Improvement Techniques")
    print("1. Data augmentation (random flips, rotations, scaling)")
    print("2. Combined BCE and Dice loss function")
    print("3. Post-processing techniques:")
    print("   - Removal of small connected components")
    print("   - Filling holes in segmentation masks")
    print("   - Morphological smoothing")
    print("4. Learning rate scheduling")

    print("\n" + "=" * 50)

# Generating summary report
create_summary_report(history, test_metrics)

"""## **Vessel Segmentation Project Summary**

**Objective**

Segment vascular structures in CTA scans using a pretrained U-Net, with enhancements for clinical applicability.

**1. Dataset & Preprocessing**

*   Source: publicly available VESSEL 12 dataset [dataset](https://zenodo.org/records/8055066).
*   Preprocessing:
 - Normalization: Scans rescaled to [0,1] using min-max normalization ((scan-min) / (max-min)).
 - Slicing: Randomly sampled 20 slices per volume during training to mitigate class imbalance.
 - Augmentation: Random flips, rotations (±15°), translations (10%), and scaling (0.9-1.1x) using torchvision.transforms.


*   Challenges:
 - Scan-mask misalignment handled by filename matching.
 - Small dataset size (14 training scans) necessitated aggressive augmentation.

**2. Model Architecture & Training**


*   Base Model: U-Net with ResNet34 encoder (pretrained on ImageNet) from segmentation_models_pytorch.
 - Choice Rationale: ResNet34 balances speed and feature extraction capability for medical images.
*  Training Setup:
 - Loss: Hybrid BCE + Dice Loss (weights: 0.5 each) to handle voxel- wise imbalance.
  - Optimizer: Adam (lr=0.001) with ReducedROnPlateau scheduler (patience=3).
  - Hardware: GPU- accelerated (CUDA) training


*   Hyperparameters:
 - Batch size: 8 (memory constraints).
 - Epochs: 5 (early stopping implied by validation metrics).

**3. Key Enhancements**


*   Data Pipeline:
 - Custom VesselDataset class with on the fly slice sampling and augmentation.
 - Test-time augmentation disabled for validation/test stes.
*   Post Processing:
 - Connected Components: removed small artifacts (min_size=100 voxels).
 - Morphological Ops: Hole filling & biniary closing (disk(2)) for smooth masks.
*   Validation:
 - Best model selected by validation Dice (saved at epoch 4 with Dice=0.978).

**4. Results & Evaluation**

Metric Raw | Prediction | Post-Processed
-----------|------------|---------------
Dice       | 0.784      | 0.785 (+0.18%)
IoU        | 0.702      | 0.704 (+0.28%)



*   Runtime:
 - Training: 133 mins (5 epochs, ~42s/batch).
 - Inference: 15.8s/scan (test set, batch size=8).

**5. Limitations**


*   Overfitting: Large train-val gap (val Dice: 0.978 -> test Dice: 0.785) suggests limited generalization
 - Potential solution: fix cross-validation, semi-supervised learning or pretraining on larger datasets.

*   Post-Processing Impact: Minimal metric improvement but enhanced visual plausability
 - Potential solution: fix optimize hyperparams (e.g., min_size) or replace with learned CRF.
*   Scalability: Slice-based approach may miss 3D context
 - Potential solution: 3D U-Net or transformer-based models

























"""